# CVOS-sensor block2
Title : Deep learning-integrated multiaxial strain sensor interface for phonetic alphabet-based communication in noisy environments

Abstract : 
	Silent speech interfaces (SSIs) offer a viable alternative to traditional microphones in capturing clear audio in noisy environments. We propose a reconceptualized SSI that reproduces voice by monitoring throat muscle movement-induced continuous multiaxial strain maps. The system integrates a computer vision-based optical strain (CVOS) sensor with deep learning-based voice reconstruction, enabling clear alphabetic communication in extreme noise environments. The CVOS sensor—comprising a soft silicone substrate with micro-markers and a tiny camera—achieves high-sensitivity marker detection and captures complex strain patterns with higher scalability and reliability compared to conventional wearable sensors. A multi-stage deep learning-based inference model, which comprehends global context, analyzes the captured patterns; on this basis, a personalized text-to-speech model generates the speaker’s voice. The algorithm conforms to the user's throat by compensating for signal variations using real-time adaptive signal processing, ensuring robustness in dynamic conditions. The alphabet-based communication, achieved by the synergy between the optimizing algorithms and interface design, demonstrated in real-world noisy scenarios confirm the practical applicability of the SSI.

![Image](https://github.com/user-attachments/assets/d5a2dd29-e669-4272-8423-103d6e9c5a49)
